# ðŸ—ï¸ KrishiSahay Technical Architecture

## System Overview

KrishiSahay employs a sophisticated multi-layered architecture combining traditional web technologies with cutting-edge AI capabilities to deliver intelligent agricultural assistance.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRESENTATION LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Frontend (HTML/CSS/JS)  â”‚  Streamlit Dashboard (Python)   â”‚
â”‚  â€¢ Interactive Chat UI   â”‚  â€¢ Admin Interface              â”‚
â”‚  â€¢ Voice Recognition     â”‚  â€¢ Analytics Dashboard          â”‚
â”‚  â€¢ Real-time Updates     â”‚  â€¢ System Monitoring            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APPLICATION LAYER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Express.js API Server   â”‚  Python Backend Services        â”‚
â”‚  â€¢ Query Processing      â”‚  â€¢ AI Model Management          â”‚
â”‚  â€¢ Response Formatting   â”‚  â€¢ Vector Operations             â”‚
â”‚  â€¢ Session Management    â”‚  â€¢ Data Pipeline Control        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI INTELLIGENCE LAYER                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  IBM Watsonx Granite LLM â”‚  FAISS Vector Database          â”‚
â”‚  â€¢ Natural Language Gen  â”‚  â€¢ Semantic Search               â”‚
â”‚  â€¢ Context Understanding â”‚  â€¢ Similarity Matching          â”‚
â”‚  â€¢ Response Enhancement  â”‚  â€¢ Fast Retrieval                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DATA LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Agricultural Knowledge  â”‚  Vector Embeddings               â”‚
â”‚  â€¢ KCC Dataset          â”‚  â€¢ Sentence Transformers         â”‚
â”‚  â€¢ Crop Information     â”‚  â€¢ Semantic Representations      â”‚
â”‚  â€¢ Expert Knowledge     â”‚  â€¢ Indexed Vectors               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”„ Data Processing Pipeline

### Stage 1: Data Ingestion & Preprocessing
```python
Raw KCC Data â†’ Cleaning â†’ Validation â†’ Standardization â†’ Storage
     â”‚              â”‚           â”‚             â”‚            â”‚
     â–¼              â–¼           â–¼             â–¼            â–¼
CSV Files    Remove Nulls   Check Format   Normalize    JSON/CSV
Excel Data   Deduplicate    Validate Q&A   Text Clean   Database
Text Files   Fix Encoding   Language Det   Tokenize     Backup
```

### Stage 2: Embedding Generation Pipeline
```python
Preprocessed Data â†’ Sentence Transformer â†’ Vector Generation â†’ Optimization
        â”‚                    â”‚                    â”‚              â”‚
        â–¼                    â–¼                    â–¼              â–¼
   Clean Text         all-MiniLM-L6-v2      384-dim vectors   Normalize
   Q&A Pairs          Model Loading         Batch Processing  Quantization
   Metadata           GPU Acceleration      Memory Efficient  Compression
```

### Stage 3: Vector Indexing & Storage
```python
Embeddings â†’ FAISS Index â†’ Optimization â†’ Persistence â†’ Validation
     â”‚            â”‚            â”‚             â”‚            â”‚
     â–¼            â–¼            â–¼             â–¼            â–¼
Float32 Array  IndexFlatL2   Add Vectors   Save Binary  Test Queries
Batch Load     Index Build   Clustering    Metadata     Performance
Memory Map     GPU Support   Quantization  Backup       Accuracy
```

### Stage 4: Query Processing Pipeline
```python
User Query â†’ Preprocessing â†’ Embedding â†’ FAISS Search â†’ Response Generation
     â”‚            â”‚             â”‚           â”‚              â”‚
     â–¼            â–¼             â–¼           â–¼              â–¼
Text Input   Clean/Normalize  Vectorize   Top-K Search   Format Output
Voice Input  Language Detect  Transform   Similarity     Rank Results
Context      Spell Check      Encode      Distance       Combine Sources
```

## ðŸ“ Dynamic File Structure

```
krishisahay/
â”œâ”€â”€ ðŸŽ¨ frontend/                          # Modern Web Interface
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html                    # Main UI with animations
â”‚   â”‚   â”œâ”€â”€ styles.css                    # Unique gradient design
â”‚   â”‚   â”œâ”€â”€ script.js                     # Interactive functionality
â”‚   â”‚   â””â”€â”€ assets/
â”‚   â”‚       â”œâ”€â”€ icons/                    # Custom agricultural icons
â”‚   â”‚       â”œâ”€â”€ sounds/                   # UI feedback sounds
â”‚   â”‚       â””â”€â”€ animations/               # Lottie animations
â”‚   â”œâ”€â”€ server.js                         # Express API server
â”‚   â””â”€â”€ package.json                      # Node.js dependencies
â”‚
â”œâ”€â”€ ðŸ§  ai-backend/                        # Python AI Services
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ query_handler.py              # FAISS query processing
â”‚   â”‚   â”œâ”€â”€ granite_llm.py                # IBM Watsonx integration
â”‚   â”‚   â”œâ”€â”€ embedding_engine.py           # Vector generation
â”‚   â”‚   â””â”€â”€ response_formatter.py         # Output formatting
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py         # Stage 1: Data cleaning
â”‚   â”‚   â”œâ”€â”€ generate_embeddings.py        # Stage 2: Vector creation
â”‚   â”‚   â”œâ”€â”€ create_faiss_index.py         # Stage 3: Index building
â”‚   â”‚   â””â”€â”€ pipeline_orchestrator.py      # Workflow management
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sentence_transformer.py       # Embedding model wrapper
â”‚   â”‚   â”œâ”€â”€ granite_client.py             # LLM client
â”‚   â”‚   â””â”€â”€ model_manager.py              # Model lifecycle
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py                     # Configuration management
â”‚   â”‚   â”œâ”€â”€ logger.py                     # Structured logging
â”‚   â”‚   â”œâ”€â”€ metrics.py                    # Performance monitoring
â”‚   â”‚   â””â”€â”€ validators.py                 # Data validation
â”‚   â”‚
â”‚   â”œâ”€â”€ app.py                            # Streamlit dashboard
â”‚   â”œâ”€â”€ setup.py                          # Automated setup
â”‚   â””â”€â”€ requirements.txt                  # Python dependencies
â”‚
â”œâ”€â”€ ðŸ“Š data/                              # Data Storage Layer
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ raw_kcc.csv                   # Original dataset
â”‚   â”‚   â”œâ”€â”€ expert_knowledge.json         # Curated expertise
â”‚   â”‚   â””â”€â”€ government_schemes.yaml       # Policy information
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ clean_kcc.csv                 # Cleaned dataset
â”‚   â”‚   â”œâ”€â”€ kcc_qa_pairs.json             # Structured Q&A
â”‚   â”‚   â””â”€â”€ metadata.json                 # Data statistics
â”‚   â”‚
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ kcc_embeddings.pkl            # Vector representations
â”‚   â”‚   â”œâ”€â”€ embedding_metadata.json       # Vector information
â”‚   â”‚   â””â”€â”€ model_info.json               # Model details
â”‚   â”‚
â”‚   â”œâ”€â”€ indices/
â”‚   â”‚   â”œâ”€â”€ faiss_index.bin               # FAISS binary index
â”‚   â”‚   â”œâ”€â”€ meta.pkl                      # Index metadata
â”‚   â”‚   â””â”€â”€ index_config.json             # Index parameters
â”‚   â”‚
â”‚   â””â”€â”€ cache/
â”‚       â”œâ”€â”€ query_cache.db                # Cached responses
â”‚       â”œâ”€â”€ embedding_cache.pkl           # Cached embeddings
â”‚       â””â”€â”€ model_cache/                  # Model artifacts
â”‚
â”œâ”€â”€ ðŸ”§ config/                            # Configuration Management
â”‚   â”œâ”€â”€ development.env                   # Dev environment
â”‚   â”œâ”€â”€ production.env                    # Prod environment
â”‚   â”œâ”€â”€ model_config.yaml                 # AI model settings
â”‚   â””â”€â”€ pipeline_config.json              # Processing parameters
â”‚
â”œâ”€â”€ ðŸ“‹ tests/                             # Comprehensive Testing
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_query_handler.py
â”‚   â”‚   â”œâ”€â”€ test_embedding_engine.py
â”‚   â”‚   â””â”€â”€ test_granite_llm.py
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_api_endpoints.py
â”‚   â”‚   â””â”€â”€ test_ui_functionality.py
â”‚   â”‚
â”‚   â”œâ”€â”€ performance/
â”‚   â”‚   â”œâ”€â”€ benchmark_queries.py
â”‚   â”‚   â”œâ”€â”€ load_testing.py
â”‚   â”‚   â””â”€â”€ memory_profiling.py
â”‚   â”‚
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ sample_queries.json
â”‚       â”œâ”€â”€ expected_responses.json
â”‚       â””â”€â”€ test_data.csv
â”‚
â”œâ”€â”€ ðŸ“š docs/                              # Documentation
â”‚   â”œâ”€â”€ API_REFERENCE.md                  # API documentation
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md               # Deployment instructions
â”‚   â”œâ”€â”€ DEVELOPMENT_SETUP.md              # Developer guide
â”‚   â”œâ”€â”€ USER_MANUAL.md                    # End-user documentation
â”‚   â””â”€â”€ TROUBLESHOOTING.md                # Common issues
â”‚
â”œâ”€â”€ ðŸš€ deployment/                        # Deployment Configurations
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile.frontend
â”‚   â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â”‚
â”‚   â”œâ”€â”€ kubernetes/
â”‚   â”‚   â”œâ”€â”€ frontend-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ backend-deployment.yaml
â”‚   â”‚   â””â”€â”€ service-configs.yaml
â”‚   â”‚
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ deploy.sh                     # Deployment script
â”‚       â”œâ”€â”€ backup.sh                     # Data backup
â”‚       â””â”€â”€ monitor.sh                    # Health monitoring
â”‚
â”œâ”€â”€ ðŸ“Š monitoring/                        # System Monitoring
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”œâ”€â”€ application.log
â”‚   â”‚   â”œâ”€â”€ error.log
â”‚   â”‚   â””â”€â”€ performance.log
â”‚   â”‚
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ query_analytics.json
â”‚   â”‚   â”œâ”€â”€ response_times.csv
â”‚   â”‚   â””â”€â”€ user_interactions.db
â”‚   â”‚
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ grafana_config.json
â”‚       â”œâ”€â”€ prometheus_rules.yml
â”‚       â””â”€â”€ alerting_rules.yml
â”‚
â”œâ”€â”€ .env                                  # Environment variables
â”œâ”€â”€ .gitignore                           # Git ignore rules
â”œâ”€â”€ README.md                            # Project overview
â”œâ”€â”€ ARCHITECTURE.md                      # This file
â””â”€â”€ LICENSE                              # MIT License
```

## ðŸ¤– Dynamic AI Components

### 1. Adaptive Query Understanding
```python
class DynamicQueryProcessor:
    def __init__(self):
        self.context_memory = {}
        self.user_patterns = {}
        self.domain_classifier = CropDomainClassifier()
    
    def process_query(self, query, user_id=None):
        # Context-aware processing
        context = self.get_user_context(user_id)
        
        # Domain classification
        domain = self.domain_classifier.classify(query)
        
        # Intent recognition
        intent = self.extract_intent(query, context)
        
        # Dynamic response routing
        return self.route_to_specialist(query, domain, intent)
```

### 2. Multi-Modal Response Generation
```python
class ResponseOrchestrator:
    def __init__(self):
        self.offline_engine = FAISSSearchEngine()
        self.online_engine = GraniteLLMEngine()
        self.fusion_layer = ResponseFusionLayer()
    
    def generate_response(self, query, mode='hybrid'):
        responses = {}
        
        # Parallel processing
        if mode in ['offline', 'hybrid']:
            responses['offline'] = self.offline_engine.search(query)
        
        if mode in ['online', 'hybrid']:
            responses['online'] = self.online_engine.generate(query)
        
        # Intelligent fusion
        return self.fusion_layer.combine(responses, query)
```

### 3. Continuous Learning Pipeline
```python
class ContinuousLearningSystem:
    def __init__(self):
        self.feedback_collector = FeedbackCollector()
        self.model_updater = ModelUpdater()
        self.performance_monitor = PerformanceMonitor()
    
    def learn_from_interactions(self):
        # Collect user feedback
        feedback = self.feedback_collector.get_recent_feedback()
        
        # Update embeddings
        if self.should_update_embeddings(feedback):
            self.update_vector_space(feedback)
        
        # Retrain models
        if self.should_retrain_models(feedback):
            self.model_updater.incremental_training(feedback)
```

## ðŸ”„ Real-Time Processing Flow

### Query Lifecycle
```mermaid
graph TD
    A[User Input] --> B{Input Type?}
    B -->|Text| C[Text Preprocessing]
    B -->|Voice| D[Speech Recognition]
    C --> E[Query Analysis]
    D --> E
    E --> F{Processing Mode?}
    F -->|Offline| G[FAISS Search]
    F -->|Online| H[LLM Generation]
    F -->|Hybrid| I[Parallel Processing]
    G --> J[Response Formatting]
    H --> J
    I --> K[Response Fusion]
    K --> J
    J --> L[User Interface]
    L --> M[Feedback Collection]
    M --> N[Learning Update]
```

## ðŸŽ¯ Performance Optimizations

### 1. Caching Strategy
- **Query Cache**: LRU cache for frequent queries
- **Embedding Cache**: Pre-computed vectors for common terms
- **Response Cache**: Cached AI responses for identical queries

### 2. Parallel Processing
- **Async Operations**: Non-blocking I/O operations
- **Multi-threading**: Parallel embedding generation
- **GPU Acceleration**: CUDA support for vector operations

### 3. Memory Management
- **Lazy Loading**: Load models on demand
- **Memory Mapping**: Efficient file access
- **Garbage Collection**: Automatic cleanup

## ðŸ”’ Security & Privacy

### Data Protection
- **Encryption**: AES-256 for data at rest
- **Secure Transmission**: HTTPS/TLS for API calls
- **Access Control**: Role-based permissions

### Privacy Measures
- **Data Anonymization**: Remove PII from queries
- **Local Processing**: Offline mode for sensitive data
- **Audit Logging**: Track all data access

## ðŸ“ˆ Scalability Architecture

### Horizontal Scaling
- **Load Balancing**: Distribute queries across instances
- **Microservices**: Independent service scaling
- **Container Orchestration**: Kubernetes deployment

### Vertical Scaling
- **Resource Optimization**: Dynamic resource allocation
- **Model Compression**: Quantized models for efficiency
- **Index Optimization**: Compressed FAISS indices

This architecture ensures KrishiSahay can handle growing user demands while maintaining high performance and accuracy in agricultural query resolution.